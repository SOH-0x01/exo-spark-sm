# Create hadoop user and group
- name: Create hadoop group
  group:
    name: "{{ hadoop_group }}"
    state: present
  tags: hadoop

- name: Create hadoop user
  user:
    name: hadoop
    group: "{{ hadoop_user }}"
    shell: "/bin/bash"
    system: yes
    state: present
  tags: hadoop

- name: Deploy hadoop sudoers inlcude
  template:
    src: "hadoop-users-sudo.j2"
    dest: "/etc/sudoers.d/XX-hadoop-users"
    owner: root
    group: root
    mode: 440
  tags: hadoop

- name: Set authorized public key for hadoop
  authorized_key:
    user: hadoop
    state: present
    key: "{{ lookup('file', './secret/hadoop/hadoop.pem.pub') }}"

# Create hadoop directories
- name: Create hadoop directories
  file:
    path: "{{ item }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
  with_items:
    - "{{ hadoop_install_dir }}"
    - "/etc/hadoop"
    - "/var/tmp/hadoop"
    - "/var/log/hadoop"
    - "/dfs/data"
  tags: hadoop

# Download and install hadoop
- name: Download hadoop binaries
  get_url:
    url: "{{ hadoop_mirror_url }}/{{ hadoop_distribution }}.tar.gz"
    dest: "/tmp/"
  tags: hadoop

- name: Unarchive hadoop to the install directory
  unarchive:
    src: "/tmp/{{ hadoop_distribution }}.tar.gz"
    dest: "{{ hadoop_install_dir }}"
    remote_src: yes
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
  tags: hadoop

- name: Create hadoop symlinks
  file:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    state: link
  with_items:
    - { src: "{{ hadoop_install_dir }}/{{ hadoop_distribution }}", dest: "{{ hadoop_home_dir }}" }
    - { src: "{{ hadoop_install_dir }}/{{ hadoop_distribution }}/etc/hadoop", dest: "/etc/hadoop/conf" }
  tags: hadoop

# Set haddoop environment
- name: Set spark envirronment
  template:
    src: templates/hadoop-profile.j2
    dest: /etc/profile.d/hadoop.sh
    owner: root
    group: root
    mode: 0644
  tags: hadoop

# Setup hadoop configuration
- name: Deploy hadoop hadoop-env.sh configuration
  template:
    src: "templates/hadoop-env.j2"
    dest: "{{ hadoop_install_dir }}/{{ hadoop_distribution }}/etc/hadoop/hadoop-env.sh"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
  tags: hadoop

- name: Deploy hadoop core-site.xml configuration
  template:
    src: templates/hadoop-core-site.j2
    dest: "{{ hadoop_install_dir }}/{{ hadoop_distribution }}/etc/hadoop/core-site.xml"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
  tags: hadoop

- name: Deploy hadoop hdfs.xml configuration
  template:
    src: "templates/hadoop-hdfs-site.j2"
    dest: "{{ hadoop_install_dir }}/{{ hadoop_distribution }}/etc/hadoop/hdfs-site.xml"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_group }}"
  tags: hadoop

- name: Clean up hadoop example and template configuration
  shell: "rm -rf {{ item }}"
  args:
    chdir: "{{ hadoop_install_dir }}/{{ hadoop_distribution }}/etc/hadoop"
  with_items:
    - "*.template"
    - "*.example"
  tags: hadoop

# Register and start the hadoop service
- name: Deploy hadoop hdfs systemd scripts
  template:
    src: "hadoop-hdfs-systemd.j2"
    dest: "/etc/systemd/system/hadoop-hdfs.service"
    owner: root
    group: root
#  notify:
#    - restart hadoop-hdfs
  tags: hadoop
