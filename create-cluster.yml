---

# Create the cloud vms
- hosts: localhost
  connection: local
  vars:
    # Constants
    exo_zone: CH-GVA-2
    exo_template: Linux Ubuntu 16.04 LTS 64-bit 10G Disk (2016-10-20-85bb6c)
    exo_instance_type: Medium
    # Parameters
    nb_nodes: 3
  post_tasks:
    - name: Wait for the ssh to be up
      become: false
      local_action: wait_for host="{{ hostvars[item].ansible_host }}" port=22 timeout=90 delay=30
      with_items: "{{ groups['all'] }}"
  roles:
    - create-cluster
    - create-context

# Generate ssh key pair for the hadoop user
- hosts: localhost
  connection: local
  vars:
    keypair_name: hadoop
  roles:
    - generate-keypair

# Setup the cluster components
- hosts: all
  vars:
    ## Java
    java_version: 8
    ## Hadoop
    hadoop_version: 2.7.3
    hadoop_user: hadoop
    hadoop_group: "{{ hadoop_user }}"
    hadoop_distribution: "hadoop-{{ hadoop_version }}"
    hadoop_mirror_url: "http://mirror.switch.ch/mirror/apache/dist/hadoop/common/{{ hadoop_distribution }}"
    hadoop_install_dir: "/usr/local/lib"
    hadoop_home_dir: "/usr/local/hadoop"
    #hadoop_env_vars:
    ## Spark
    spark_version: 2.1.0
    spark_user: spark
    spark_group: "{{ spark_user }}"
    spark_distribution: "spark-{{ spark_version }}-bin-hadoop2.7"
    spark_mirror_url: "http://d3kbcqa49mib13.cloudfront.net"
    spark_install_dir: "/usr/local/lib"
    spark_home_dir: "/usr/local/spark"
    spark_master_port: 7077
    spark_master_ui_port: 8080
    spark_worker_port: 7078
    spark_worker_ui_port: 8081
    #spark_env_vars:
  become: true
  roles:
    - setup-cluster

# Start the services
- hosts: masters
  tasks:
    - name: format hdfs (unless it's already been done)
      shell: "hadoop namenode -format"
    - name: start hadoop-dfs
      service:
        name: hadoop-dfs
        state: started
        enabled: yes
        daemon_reload: yes
    - name: start hadoop-yarn
      service:
        name: hadoop-yarn
        state: started
        enabled: yes
        daemon_reload: yes
    - name: start spark-master
      service:
        name: spark-master
        state: started
        enabled: yes
        daemon_reload: yes

- hosts: workers
  tasks:
    - name: start spark-worker
      service:
        name: spark-worker
        state: started
        enabled: yes
        daemon_reload: yes
